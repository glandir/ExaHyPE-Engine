Packed-Type: short int;

class exahype::dastgen::State {    
  /**
   * Consult Peano guidebook Section 6.3.2
   */
  persistent parallelise int maxRefinementLevelAllowed;
  
  /**
   * This enum is used to specify
   * which data we want to merge in the
   * Merging mapping.
   * 
   * Note that we define sending and merging here 
   * as operation between individual cells not
   * just between subdomains belong to different threads
   * or MPI processes.
   * 
   * For example, an ADER-DG solver might send
   * data to its face data arrays or a neighbour rank's heap in one
   * iteration.
   * In the next iteration, the data is picked up and merrged by its 
   * direct neighbour which might be a local cell
   * or a cell belonging to another rank.
   */
  enum MergeMode {
    /**
     * Do not merge anything.
     */
    MergeNothing,

    /**
     * This is one of the modes
     * for the standard time stepping
     * algorithm.
     *
     * This mode should be set before
     * performing the correction phase.
     *
     * Time step data exchange is
     * a reduction-broadcast operation.
     */
    BroadcastAndMergeTimeStepData,
    
    /**
     * This is one of the modes
     * for the standard time stepping
     * algorithm.
     *
     * This mode should be set before
     * performing the prediction phase.
     *
     * In principal, face data exchange is
     * direct neighbour communication.
     * However if we consider adaptive meshes,
     * face data exchange also includes
     * master-worker and worker-master
     * communication.
     */
    MergeFaceData,
    
    /**
     * Drop face data.
     */
    DropFaceData,
    
    /**
     * This is the default mode if you use
     * fused time stepping.
     *
     * In this case, we exchange
     * time step as well as
     * face data.
     */
    BroadcastAndMergeTimeStepDataAndMergeFaceData,
    
    /**
     * Broadcast time step data from the 
     * master to the workers 
     * and drop face data.
     */
    BroadcastAndMergeTimeStepDataAndDropFaceData
  };

  parallelise persistent MergeMode mergeMode;

  /**
   * This enum is used to specify
   * which data we want to send in the
   * Sending mapping.
   * 
   * Note that we define sending and merging here 
   * as operations between individual cells not
   * just between subdomains belong to different threads
   * or MPI processes. 
   * 
   * For example, an ADER-DG solver might send
   * data to its face data arrays or a neighbour rank's heap in
   * one iteration.
   * In the next iteration, the data is picked up and merrged by its 
   * direct neighbour which might be a local cell
   * or a cell belonging to another rank.
   */
  enum SendMode {
    /**
     * Do not send anything.
     */
    SendNothing,

    /**
     * This is one of the modes
     * for the standard time stepping
     * algorithm.
     *
     * This mode should be set before
     * performing the correction phase.
     *
     * Time step data exchange is
     * a reduction-broadcast operation.
     */
    ReduceAndMergeTimeStepData,
    /**
     * This is one of the modes
     * for the standard time stepping
     * algorithm.
     *
     * This mode should be set before
     * performing the prediction phase.
     *
     * In principal, face data exchange is
     * direct neighbour communication.
     * However if we consider adaptive meshes,
     * face data exchange also includes
     * as master-worker and worker-master
     * communication.
     */
    SendFaceData,
    /**
     * Choose this mode if you use
     * fused time stepping.
     *
     * In this case, we exchange
     * time step as well as
     * face data. We thus overlap the
     * reduction-broadcast with
     * the master-worker and
     * worker-master communication.
     */
    ReduceAndMergeTimeStepDataAndSendFaceData
  };
  parallelise persistent SendMode sendMode;
  
  /**
   * This flag influences the behaviour of the Predictor,
   * TimeStepSizeComputation, SolutionUpdate, Merging and
   * Sending mappings by selecting only the solvers that
   * are active in the given algorithmic section.
   */
  enum AlgorithmicSection {
   	/*
   	 * The runner is currently 
   	 * performing a normal ADER-DG time step.
   	 */
   	TimeStepping,
   	
   	/**
   	 * The runner is recomputing the solution of 
   	 * troubled cells on the finest mesh level.
   	 * No mesh refinement is necessary.
   	 * 
   	 * The following scenario causes the runner
   	 * to switch to this algorithmic section:
   	 * 
   	 * A compute cell (Cell) was marked as troubled on
     * the finest mesh level. No 
     * cell of type Descendant/EmptyDescendant
     * was marked with a LimiterStatus other than Ok. 
   	 */
   	LocalRecomputation,
   	
   	/**
   	 * The runner is redoing the last ADER-DG time
   	 * step completely but performs some mesh
   	 * refinement beforehand.
   	 * 
   	 * More precisely, the runner will fist trigger a rollback to
   	 * the previous time step> It will then trigger mesh refinement
   	 * until a troubled compute cell and all its compute cell
   	 * neighours are placed on the finest mesh level.
   	 * Next it will trigger the computation of a new
   	 * time step size and then, the computation of 
   	 * a new space-time predictor.
   	 * Afterwards a solution update in all cells is performed.
   	 * Now, the solution of the cells has evolved
   	 * to the anticipated time step.
   	 * Lastly, the runner will 
     * trigger a recomputation of the predictor.
   	 * 
   	 * The following scenario causes the runner
     * to switch to this algorithmic section:
   	 * 
   	 * Scenario 1:
   	 * A compute cell was marked as troubled on a
   	 * mesh level coarser than the finest one.
   	 *   
   	 * Scenario 2: A cell of type Descendant/EmptyDescendant
   	 * was marked with a LimiterStatus other than Ok.
   	 */
   	APosterioriRefinement,
   	
   	/**
   	 * The runner performs mesh refinement according to the
   	 * user's refinement criterion or the regular limiter status
   	 * flagging, i.e. the LimiterStatus updates caused by a 
   	 * regularly moving limiter domain.
   	 * 
   	 * In this case, the runner will trigger mesh refinement, and
   	 * the recomputation of the time step size. Lastly, it will 
   	 * trigger a recomputation of the predictor.
   	 */
   	APrioriRefinement
  };
  parallelise persistent AlgorithmicSection _algorithmicSection;
  
  /**
   * If this flag is set, the solvers
   * are notified that they might need
   * to reinitialise their time step sizes 
   * and time stamps before a new time step
   * is started.
   * 
   * This is usually the case if the
   * mesh has been updated after the computation
   * of the last solution. 
   * 
   * The ADER-DG solver, e.g., needs then to 
   * overwrite the predictor time step size 
   * of as well as the predictor time stamp
   * before startNewTimeStep() is called for the solver
   * since both will be used as corrector quantities in the next iteration.
   */
  persistent bool reinitTimeStepData;
  
  /**
   * This flag indicates if at least one solver
   * has performed a time step with an 
   * instable (too large) time step size and
   * thus needs to be recomputed.
   * This can happen when we run the fused ADER-DG
   * variant. 
   * 
   * Needs to be reset after the affected
   * solvers have been rerun with a
   * stable time step size.
   * 
   * <h2>MPI</h2>
   * This flag does not need to be parallelised since
   * we use it only for the global master rank.
   */
  persistent bool stabilityConditionOfOneSolverWasViolated;
  
  /**
   * A factor in the range (0,1] that
   * is used for reseting the time step sizes
   * of an ADER-DG solver.
   * 
   * The reset corrector and predictor time step sizes
   * are reset to a stable time step size times this factor. 
   */
  persistent double timeStepSizeWeightForPredictionRerun;
};
