/**
 * This file is part of the ExaHyPE project.
 * Copyright (c) 2016  http://exahype.eu
 * All rights reserved.
 *
 * The project has received funding from the European Union's Horizon
 * 2020 research and innovation programme under grant agreement
 * No 671698. For copyrights and licensing, please consult the webpage.
 *
 * Released under the BSD 3 Open Source License.
 * For the full license text, see LICENSE.txt
 **/

#include <cstring>

#include "tarch/la/Vector.h"
#include "tarch/multicore/Loop.h"
#include "peano/datatraversal/autotuning/Oracle.h"

#include "../../../../DGMatrices.h"
#include "../../../../GaussLegendreQuadrature.h"
#include "../../../../KernelUtils.h"

#include "SharedMemoryLabels.h"

#if DIMENSIONS == 3

namespace kernels {
namespace aderdg {
namespace generic {
namespace c {

namespace {

  /*
   * For the linear kernels, we need the material parameters in the
   * space-time predictor lQi, time-averaged predictor lQhi,
   * and extrapolated predictor lQhbnd.
   * Currently we simply copy them over from the solution array.
   *
   */
  template <bool useSource, bool useFlux, bool useNCP, typename SolverType>
  void aderPicardLoopNonlinear(SolverType& solver,
                               const double* luh, const double dt,
                               const tarch::la::Vector<DIMENSIONS, double>& dx,
                               double* lQi, double *lQi_old, double* rhs,
                               double* lFi, double* gradQ) {
    constexpr int numberOfVariables  = SolverType::NumberOfVariables;
    constexpr int numberOfParameters = SolverType::NumberOfParameters;
    constexpr int numberOfData       = numberOfVariables+numberOfParameters;
    constexpr int order              = SolverType::Order;
    constexpr int basisSize          = order+1;
    constexpr int basisSize2         = basisSize * basisSize;
    constexpr int basisSize4         = basisSize2 * basisSize2;

    assertion(numberOfVariables>=0);
    assertion(numberOfParameters>=0);

    idx4 idx_luh(basisSize, basisSize, basisSize, numberOfData);

    idx5 idx_lQi(basisSize, basisSize, basisSize, basisSize, numberOfData);

    idx6 idx_lFi(basisSize, basisSize, basisSize, basisSize, DIMENSIONS + 1, numberOfVariables);
    // (t,z,y,x,dim,var)
    
    // 1. Trivial initial guess
    auto grainSizeTrivialGuess = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsTrivialGuessLoop);
    //for (int i = 0; i < basisSize; i++) { // i == z
    pfor(i,0,basisSize,grainSizeTrivialGuess.getGrainSize())
    for (int j = 0; j < basisSize; j++) { // j == y
      for (int k = 0; k < basisSize; k++) { // k == x
        for (int l = 0; l < basisSize; l++) { // l==t
          // Fortran: lQi(m,:,k,j,i) = luh(m,k,j,i)
          std::copy_n (luh + idx_luh(i, j, k, 0), numberOfData,
                       lQi + idx_lQi(i, j, k, l, 0));
        }
      }
    }
    endpfor
    grainSizeTrivialGuess.parallelSectionHasTerminated();

    // 3. Discrete Picard iterations
    constexpr int MaxIterations = 2 * (order + 1);
    // right-hand side
    idx5 idx_rhs(basisSize, basisSize, basisSize, basisSize, numberOfVariables); // idx_rhs(t,z,y,x,nVar)
    // spatial gradient of q
    // idx_gradQ(z,y,x,t,nDim,nVar)
    idx6 idx_gradQ(basisSize, basisSize, basisSize, basisSize, DIMENSIONS, numberOfVariables);

    for (int iter = 0; iter < MaxIterations; iter++) {
      // Save old space-time DOF
      std::memcpy(lQi_old, lQi, basisSize4 * numberOfData * sizeof(double));

      for (int i = 0; i < basisSize; i++) {  // time DOF
        // Compute the fluxes
        if(useFlux) {
          auto grainSizeFluxSourceNCPLoop = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsFluxSourceNCPLoop);
          //for (int j = 0; j < basisSize; j++) { // z
          pfor(j,0,basisSize,grainSizeFluxSourceNCPLoop.getGrainSize())
          for (int k = 0; k < basisSize; k++) { // y
            for (int l = 0; l < basisSize; l++) { // x
              // Call PDE fluxes
              const double* Q = lQi + idx_lQi(j, k, l, i, 0);
              double* F[3];
              F[0] = lFi + idx_lFi(i, j, k, l, 0, 0);
              F[1] = lFi + idx_lFi(i, j, k, l, 1, 0);
              F[2] = lFi + idx_lFi(i, j, k, l, 2, 0);
              solver.flux(Q, F);

              // the algebraic source call moved together with ncp products
              // to the end.
            }
          }
          endpfor
          grainSizeFluxSourceNCPLoop.parallelSectionHasTerminated();
        }

        // Compute the contribution of the initial condition uh to the right-hand side (rhs0)
        auto grainSizeCopyRhs = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsCopyRhs);
        //for (int j = 0; j < basisSize; j++) { // z
        pfor(j,0,basisSize,grainSizeCopyRhs.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // y
          for (int l = 0; l < basisSize; l++) { // x
            const double weight = kernels::gaussLegendreWeights[order][j] *
                kernels::gaussLegendreWeights[order][k] *
                kernels::gaussLegendreWeights[order][l];
            for (int m = 0; m < numberOfVariables; m++) {
              rhs[idx_rhs(i, j, k, l, m)] =
                  weight * kernels::F0[order][i] * luh[idx_luh(j, k, l, m)];
            }
          }
        }
        endpfor
        grainSizeCopyRhs.parallelSectionHasTerminated();

        // Compute gradients only if nonconservative contributions have to be
        // computed.
        if(useNCP) {
          std::memset(gradQ, 0, basisSize4 * DIMENSIONS * numberOfVariables * sizeof(double));
        }

        // Compute the "derivatives" (contributions of the stiffness matrix)
        // x direction (independent from the y and z derivatives)
        auto grainSizeComputeDerivatives = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsComputeDerivatives);
        //for (int j = 0; j < basisSize; j++) { // z
        pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // y
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[0];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // x
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                if(useFlux) {
                  rhs[idx_rhs(i, j, k, l, m)] -= updateSize *
                      lFi[idx_lFi(i, j, k, n, 0, m)] *
                      kernels::Kxi[order][n][l];
                }
                if(useNCP) {
                  gradQ[idx_gradQ(j, k, l, i, /*x*/0, m)] += 1.0 / dx[0] *
                      lQi[idx_lQi(j, k, n, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
        endpfor

        // y direction (independent from the x and z derivatives)
        //for (int j = 0; j < basisSize; j++) { // z
        pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // x
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[1];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // y
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                if(useFlux) {
                  rhs[idx_rhs(i, j, l, k, m)] -= updateSize *
                      lFi[idx_lFi(i, j, n, k, 1, m)] *
                      kernels::Kxi[order][n][l];
                }
                if(useNCP) {
                  gradQ[idx_gradQ(j, l, k, i, /*y*/1, m)] += 1.0 / dx[1] *
                      lQi[idx_lQi(j, n, k, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
        endpfor

        // z direction (independent from the x and y derivatives)
        //for (int j = 0; j < basisSize; j++) { // y
        pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // x
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[2];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // z
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                if(useFlux) {
                  rhs[idx_rhs(i, l, j, k, m)] -= updateSize *
                      lFi[idx_lFi(i, n, j, k, 2, m)] *
                      kernels::Kxi[order][n][l];
                }
                if(useNCP) {
                  gradQ[idx_gradQ(l, j, k, i, /*z*/2, m)] += 1.0 / dx[2] *
                      lQi[idx_lQi(n, j, k, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
        endpfor

        if(useSource || useNCP) {
          // source
          auto grainSizeSourceNCP = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsSourceNCP);
          //for (int j = 0; j < basisSize; j++) { // z
          pfor(j,0,basisSize,grainSizeSourceNCP.getGrainSize())
          for (int k = 0; k < basisSize; k++) { // y
            for (int l = 0; l < basisSize; l++) { // x
              const double weight = kernels::gaussLegendreWeights[order][i] *
                  kernels::gaussLegendreWeights[order][j] *
                  kernels::gaussLegendreWeights[order][k] *
                  kernels::gaussLegendreWeights[order][l];
              const double updateSize = weight * dt;
              double* S = lFi + idx_lFi(i, j, k, l, 3, 0);

              // by intention, gradQ is undefined here if useNCP is not true.
              // This is because algebraicSource is only a function of Q and S.
              solver.fusedSource(&lQi[idx_lQi(j, k, l, i, 0)], &gradQ[idx_gradQ(j, k, l, i, 0, 0)], S);

              for (int m = 0; m < numberOfVariables; m++) {
                rhs[idx_rhs(i, j, k, l, m)] += updateSize * S[m];
              }
            }
          }
          endpfor
          grainSizeSourceNCP.parallelSectionHasTerminated();
        }
      }  // end time dof

      // Zero out variables in lQi
      if (numberOfParameters==0) {
        std::memset(lQi, 0, basisSize4 * numberOfVariables * sizeof(double));
      } else {
        for (int i = 0; i < basisSize; i++) { // i == z
          for (int j = 0; j < basisSize; j++) { // j == y
            for (int k = 0; k < basisSize; k++) { // k == x
              for (int l = 0; l < basisSize; l++) { // l==t
                std::fill_n (lQi + idx_lQi(i, j, k, l, 0), numberOfVariables, 0.0);
              }
            }
          }
        }
      }

      // 4. Multiply with (K1)^(-1) to get the discrete time integral of the
      // discrete Picard iteration
      auto grainSizeDiscreteTimeIntegral = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsDiscreteTimeIntegral);
      //for (int i = 0; i < basisSize; i++) {
      pfor(i,0,basisSize,grainSizeDiscreteTimeIntegral.getGrainSize())
      for (int j = 0; j < basisSize; j++) {
        for (int k = 0; k < basisSize; k++) {
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double iweight = 1.0 / weight;

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // time
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) { // time
                lQi[idx_lQi(i, j, k, l, m)] += iweight *
                    rhs[idx_rhs(n, i, j, k, m)] *
                    kernels::iK1[order][l][n];
                // TODO: Check if we store iK1 or rather its transpose
              }
            }
          }
        }
      }
      endpfor
      grainSizeDiscreteTimeIntegral.parallelSectionHasTerminated();

      // 5. Exit condition
      constexpr double tol = 1e-7;
      double sq_res = 0.0;
      for (int i = 0; i < basisSize4 * numberOfData; i++) {
        sq_res += (lQi_old[i] - lQi[i]) * (lQi_old[i] - lQi[i]);
      }
      if (sq_res < tol * tol) {
        break;
      }

      if (iter == MaxIterations) {  // No convergence after last iteration
        static tarch::logging::Log _log("kernels::aderdg::generic::c");
        logWarning("aderPicardLoopNonlinear(...)",
                   "|res|^2=" << sq_res << " > |tol|^2=" << tol * tol << " after "
                   << iter << " iterations. Solver seems not to "
                   "have converged properly within "
                   "maximum number of iteration steps");
      }
    }  // end iter
  }

  /*
   *  Immediately compute the time - averaged space - time polynomials
   *
   *  We have to consider that we store parameters in lQi
   *  and lQhi, and have to adjust the index accordingly.
   */
  template <bool useSource, bool useFlux, bool useNCP, int numberOfVariables, int numberOfParameters, int basisSize>
  void aderPredictorNonlinear(const double* lQi, const double* lFi,
                              double* lQhi,double* lFhi_x, double* lFhi_y, double* lFhi_z,
                              double* lShi) {
    // Immediately compute the time - averaged space - time polynomials

    constexpr int basisSize2 = basisSize * basisSize;
    constexpr int basisSize3 = basisSize2 * basisSize;
    constexpr int order      = basisSize - 1;

    constexpr int numberOfData = numberOfVariables+numberOfParameters;

    idx5 idx_lQi(basisSize, basisSize, basisSize, basisSize, numberOfData);

    idx6 idx_lFi(basisSize, basisSize, basisSize, basisSize, DIMENSIONS + 1, numberOfVariables);

    idx4 idx_lQhi(basisSize, basisSize, basisSize, numberOfData);

    idx4 idx_lFhi(basisSize, basisSize, basisSize, numberOfVariables);
    idx4 idx_lShi(basisSize, basisSize, basisSize, numberOfVariables);

    std::fill_n(lQhi, basisSize3 * numberOfData, 0.0);

    //if(useFlux) {
    std::fill_n(lFhi_x, basisSize3 * numberOfVariables, 0.0);
    std::fill_n(lFhi_y, basisSize3 * numberOfVariables, 0.0);
    std::fill_n(lFhi_z, basisSize3 * numberOfVariables, 0.0);
    //}
    std::fill_n(lShi,   basisSize3 * numberOfVariables, 0.0);

    for (int i = 0; i < basisSize; i++) {
      for (int j = 0; j < basisSize; j++) {
        for (int k = 0; k < basisSize; k++) {
          for (int l = 0; l < numberOfVariables; l++) {
            // Matrix-Vector Products
            for (int m = 0; m < basisSize; m++) {
              if(useFlux) {
                // Fortran: lFhi_x(:,k,j,i) = lFh(:,1,k,j,i,:) * wGPN(:)
                lFhi_x[idx_lFhi(i, j, k, l)] +=
                    lFi[idx_lFi(m, i, j, k, 0, l)] *
                    kernels::gaussLegendreWeights[order][m];

                // Fortran: lFhi_y(:,j,k,i) = lFh(:,2,:k,j,i,:) * wGPN(:)
                lFhi_y[idx_lFhi(i, k, j, l)] +=
                    lFi[idx_lFi(m, i, j, k, 1, l)] *
                    kernels::gaussLegendreWeights[order][m];

                // Fortran: lFhi_z(:,i,k,j) = lFh(:,3,k,j,i,:) * wGPN(:)
                lFhi_z[idx_lFhi(j, k, i, l)] +=
                    lFi[idx_lFi(m, i, j, k, 2, l)] *
                    kernels::gaussLegendreWeights[order][m];
              }
              if(useSource || useNCP) {
                // Fortran: lShi(:,k,j,i) = lSh(:,k,j,i,:) * wGPN(:)
                lShi[idx_lShi(i, j, k, l)] +=
                    lFi[idx_lFi(m, i, j, k, 3, l)] *
                    kernels::gaussLegendreWeights[order][m];
              }
            }
          }
          for (int l = 0; l < numberOfData; l++) {
            // Matrix-Vector Products
            for (int m = 0; m < basisSize; m++) {
              // Fortran: lQhi(:,k,j,i) = lQi(:,:,k,j,i) * wGPN(:)
              lQhi[idx_lQhi(i, j, k, l)] +=
                  lQi[idx_lQi(i, j, k, m, l)] *
                  kernels::gaussLegendreWeights[order][m];
            }
          }
        }
      }
    }
  }

  template <bool useFlux, int numberOfVariables, int numberOfParameters, int basisSize>
  void aderExtrapolatorNonlinear(const double* lQhi, const double* lFhi_x,
                                 const double* lFhi_y, const double* lFhi_z, double* lQhbnd, double* lFhbnd) {
    // Compute the boundary-extrapolated values for Q and F*n
    constexpr int basisSize2 = basisSize * basisSize;
    constexpr int order      = basisSize - 1;

    constexpr int numberOfData = numberOfVariables+numberOfParameters;

    idx4 idx_lQhi(basisSize, basisSize, basisSize, numberOfData);
    idx4 idx_lFhi(basisSize, basisSize, basisSize, numberOfVariables);

    idx4 idx_lQhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfData);
    idx4 idx_lFhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfVariables);

    std::fill_n(lQhbnd, 2 * DIMENSIONS * basisSize2 * numberOfData, 0.0);
    // in princple, we should ignore the lFhbnd but we can also zero them out.
    // zeroing them keeps CCZ4 GaugeWave stable for more time steps but not
    // for long time.
    //if(useFlux) {
    std::fill_n(lFhbnd, 2 * DIMENSIONS * basisSize2 * numberOfVariables, 0.0);
    //}

    // x-direction: face 1 (left) and face 2 (right)
    for (int i = 0; i < basisSize; i++) {
      for (int j = 0; j < basisSize; j++) {
        // Matrix-Vector Products
        if(useFlux) {
          for (int k = 0; k < numberOfVariables; k++) {
            for (int l = 0; l < basisSize; l++) {
              // Fortran: lFhbnd(:,j,i,1) = lFhi_x(:,:,j,i) * FLCoeff(:)
              lFhbnd[idx_lFhbnd(0, i, j, k)] +=
                  lFhi_x[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

              // Fortran: lFhbnd(:,j,i,2) = lFhi_x(:,:,j,i) * FRCoeff(:)
              lFhbnd[idx_lFhbnd(1, i, j, k)] +=
                  lFhi_x[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
            }
          }
        }
        for (int k = 0; k < numberOfData; k++) {
          for (int l = 0; l < basisSize; l++) {
            // Fortran: lQhbnd(:,j,i,1) = lQhi(:,:,j,i) * FLCoeff(:)
            lQhbnd[idx_lQhbnd(0, i, j, k)] +=
                lQhi[idx_lQhi(i, j, l, k)] * kernels::FLCoeff[order][l];

            // Fortran: lQhbnd(:,j,i,2) = lQhi(:,:,j,i) * FRCoeff(:)
            lQhbnd[idx_lQhbnd(1, i, j, k)] +=
                lQhi[idx_lQhi(i, j, l, k)] * kernels::FRCoeff[order][l];
          }
        }
      }
    }

    // y-direction: face 3 (left) and face 4 (right)
    for (int i = 0; i < basisSize; i++) {
      for (int j = 0; j < basisSize; j++) {
        if(useFlux) {
          for (int k = 0; k < numberOfVariables; k++) {
            // Matrix-Vector Products
            for (int l = 0; l < basisSize; l++) {
              // Fortran: lFhbnd(:,j,i,3) = lFhi_y(:,:,j,i) * FLCoeff(:)
              lFhbnd[idx_lFhbnd(2, i, j, k)] +=
                  lFhi_y[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

              // Fortran: lFhbnd(:,j,i,4) = lFhi_y(:,:,j,i) * FRCoeff(:)
              lFhbnd[idx_lFhbnd(3, i, j, k)] +=
                  lFhi_y[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
            }
          }
        }
        for (int k = 0; k < numberOfData; k++) {
          // Matrix-Vector Products
          for (int l = 0; l < basisSize; l++) {
            // Fortran: lQhbnd(:,j,i,3) = lQhi(:,j,:,i) * FLCoeff(:)
            lQhbnd[idx_lQhbnd(2, i, j, k)] +=
                lQhi[idx_lQhi(i, l, j, k)] * kernels::FLCoeff[order][l];

            // Fortran: lQhbnd(:,j,i,4) = lQhi(:,j,:,i) * FRCoeff(:)
            lQhbnd[idx_lQhbnd(3, i, j, k)] +=
                lQhi[idx_lQhi(i, l, j, k)] * kernels::FRCoeff[order][l];
          }
        }
      }
    }

    // z-direction: face 5 (left) and face 6 (right)
    for (int i = 0; i < basisSize; i++) {
      for (int j = 0; j < basisSize; j++) {
        if(useFlux) {
          for (int k = 0; k < numberOfVariables; k++) {
            // Matrix-Vector Products
            for (int l = 0; l < basisSize; l++) {
              // Fortran: lFhbnd(:,j,i,5) = lFhi_z(:,:,j,i) * FLCoeff(:)
              lFhbnd[idx_lFhbnd(4, i, j, k)] +=
                  lFhi_z[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

              // Fortran: lFhbnd(:,j,i,6) = lFhi_z(:,:,j,i) * FRCoeff(:)
              lFhbnd[idx_lFhbnd(5, i, j, k)] +=
                  lFhi_z[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
            }
          }
        }
        for (int k = 0; k < numberOfData; k++) {
          // Matrix-Vector Products
          for (int l = 0; l < basisSize; l++) {
            // Fortran: lQhbnd(:,j,i,5) = lQhi(:,j,i,:) * FLCoeff(:)
            lQhbnd[idx_lQhbnd(4, i, j, k)] +=
                lQhi[idx_lQhi(l, i, j, k)] * kernels::FLCoeff[order][l];

            // Fortran: lQhbnd(:,j,i,6) = lQhi(:,j,i,:) * FRCoeff(:)
            lQhbnd[idx_lQhbnd(5, i, j, k)] +=
                lQhi[idx_lQhi(l, i, j, k)] * kernels::FRCoeff[order][l];
          }
        }
      }
    }
  }
  
  template <int numberOfVariables,int numberOfParameters,int basisSize>
  void aderTimeAveragingExtrapolatorNonlinear(
      const double* lQi, const double* lFi,
      double* lQhbnd, double* lFhbnd) {
    // Compute the boundary-extrapolated values for Q and F*n

    const int order      = basisSize - 1;
    const int basisSize2 = basisSize*basisSize;
    
    constexpr int numberOfData = numberOfVariables+numberOfParameters;

    idx5 idx_lQi(basisSize, basisSize, basisSize, basisSize, numberOfData);                   // (z,y,x,t,var/param)
    idx6 idx_lFi(basisSize, basisSize, basisSize, basisSize, DIMENSIONS+1,numberOfVariables); // (t,z,y,x,flux/source,var)

    idx4 idx_lQhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfData);
    idx4 idx_lFhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfVariables);
    
    std::fill_n(lQhbnd, 2 * DIMENSIONS * basisSize2 * numberOfData,      0.0);
    std::fill_n(lFhbnd, 2 * DIMENSIONS * basisSize2 * numberOfVariables, 0.0);
    // x-faces: (z,y,var/par)
    // y-faces: (z,x,var/par)
    // z-faces: (y,x,var/par)

    for (int i=0; i < basisSize; i++) { // loop over time dof
      // x-direction: face 0 (left) and face 1 (right)
      for (int j = 0; j < basisSize; j++) { // z
        for (int k = 0; k < basisSize; k++) { // y 
          // Matrix-Vector Products
          for (int l = 0; l < numberOfVariables; l++) {
            for (int n = 0; n < basisSize; n++) { // x
              lFhbnd[idx_lFhbnd(0, j, k, l)] += 
                  lFi[idx_lFi(i, j, k, n, 0, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lFhbnd[idx_lFhbnd(1, j, k, l)] += 
                  lFi[idx_lFi(i, j, k, n, 0, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];
            }
          }
          // Matrix-Vector Products
          for (int l = 0; l < numberOfData; l++) {
            for (int n = 0; n < basisSize; n++) { // x
              lQhbnd[idx_lQhbnd(0, j, k, l)] += 
                  lQi[idx_lQi(j, k, n, i, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lQhbnd[idx_lQhbnd(1, j, k, l)] += 
                  lQi[idx_lQi(j, k, n, i, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];
            }
          }
        }
      }

      // y-direction: face 2 (front) and face 3 (back)
      for (int j = 0; j < basisSize; j++) { // z
        for (int k = 0; k < basisSize; k++) { // x 
          // Matrix-Vector Products
          for (int l = 0; l < numberOfVariables; l++) {
            for (int n = 0; n < basisSize; n++) { // y  
              lFhbnd[idx_lFhbnd(2, j, k, l)] +=  
                  lFi[idx_lFi(i, j, n, k, 1, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lFhbnd[idx_lFhbnd(3, j, k, l)] += 
                  lFi[idx_lFi(i, j, n, k, 1, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];
            }
          }
          // Matrix-Vector Products
          for (int l = 0; l < numberOfData; l++) {
            for (int n = 0; n < basisSize; n++) { // y
              lQhbnd[idx_lQhbnd(2, j, k, l)] += 
                  lQi[idx_lQi(j, n, k, i, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lQhbnd[idx_lQhbnd(3, j, k, l)] += 
                  lQi[idx_lQi(j, n, k, i, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

            }
          }
        }
      }

      // z-direction: face 4 (front) and face 5 (back)
      for (int j = 0; j < basisSize; j++) { // y
        for (int k = 0; k < basisSize; k++) { // x 
          // Matrix-Vector Products
          for (int l = 0; l < numberOfVariables; l++) {
            for (int n = 0; n < basisSize; n++) { // z
              lFhbnd[idx_lFhbnd(4, j, k, l)] +=
                  lFi[idx_lFi(i, n, j, k, 2, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lFhbnd[idx_lFhbnd(5, j, k, l)] +=
                  lFi[idx_lFi(i, n, j, k, 2, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];
            }
          }
          // Matrix-Vector Products
          for (int l = 0; l < numberOfData; l++) {
            for (int n = 0; n < basisSize; n++) { // z
              lQhbnd[idx_lQhbnd(4, j, k, l)] +=
                  lQi[idx_lQi(n, j, k, i, l)] * 
                  kernels::FLCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];

              lQhbnd[idx_lQhbnd(5, j, k, l)] +=
                  lQi[idx_lQi(n, j, k, i, l)] * 
                  kernels::FRCoeff[order][n] * 
                  kernels::gaussLegendreWeights[order][i];
            }
          }
        }
      }
    }
  } // time dof loop

}  // namespace

template <bool useSource, bool useFlux, bool useNCP, typename SolverType>
void spaceTimePredictorNonlinear(
    SolverType& solver,
    double*  lQhbnd, double* lFhbnd,
    double** tempSpaceTimeUnknowns,
    double** tempSpaceTimeFluxUnknowns,
    double*  tempUnknowns,
    double*  tempFluxUnknowns,
    double*  tempStateSizedVector,
    const double* const luh,
    const tarch::la::Vector<DIMENSIONS, double>& dx,
    double dt
) {
  constexpr int numberOfVariables  = SolverType::NumberOfVariables;
  constexpr int numberOfParameters = SolverType::NumberOfParameters;
  constexpr int basisSize          = SolverType::Order+1;

  double* lQi     = tempSpaceTimeUnknowns[0];
  double* lQi_old = tempSpaceTimeUnknowns[1];
  double* rhs     = tempSpaceTimeUnknowns[2];

  // Give nullptrs in case certain PDE features are not used in order to detect
  // wrong memory access patterns more quickly.

  double* lFi     = tempSpaceTimeFluxUnknowns[0]; // lFi also stores the source
  double* gradQ   = useNCP ? tempSpaceTimeFluxUnknowns[1] : nullptr; // size: basisSize3 * DIMENSIONS * numberOfVariables

  aderPicardLoopNonlinear<useSource, useFlux, useNCP, SolverType>(
      solver, luh, dt, dx, lQi, lQi_old, rhs, lFi, gradQ
  );
  
#ifdef NO_TIME_AVERAGING
  aderTimeAveragingExtrapolatorNonlinear<numberOfVariables,numberOfParameters, basisSize>(
      lQi,
      lFi,
      lQhbnd, lFhbnd);
#else
  constexpr int basisSize2         = basisSize * basisSize;
  constexpr int basisSize3         = basisSize2 * basisSize;
  
  double *lQhi    = tempUnknowns;
  double *lFhi    = tempFluxUnknowns;

  aderPredictorNonlinear<useSource, useFlux, useNCP, numberOfVariables, numberOfParameters, basisSize>(
      lQi, lFi, lQhi,
      &lFhi[0 * basisSize3 * numberOfVariables],  // lFhi_x
      &lFhi[1 * basisSize3 * numberOfVariables],  // lFhi_y
      &lFhi[2 * basisSize3 * numberOfVariables],  // lFhi_z
      &lFhi[3 * basisSize3 * numberOfVariables]   // lShi
  );

  aderExtrapolatorNonlinear<useFlux, numberOfVariables, numberOfParameters, basisSize>(
      lQhi,
      &lFhi[0 * basisSize3 * numberOfVariables],  // lFhi_x
      &lFhi[1 * basisSize3 * numberOfVariables],  // lFhi_y
      &lFhi[2 * basisSize3 * numberOfVariables],  // lFhi_z
      lQhbnd, lFhbnd);
#endif
  
  // TODO(Dominic): Keep a while for debugging
//  double* lQhbnd2 = new double[2 * DIMENSIONS * basisSize2 *  (numberOfVariables+numberOfParameters)];
//  double* lFhbnd2 = new double[2 * DIMENSIONS * basisSize2 *  numberOfVariables];
  
  // TODO(Dominic): Keep a while for debugging
//  idx4 idx_lFhbnd(2*DIMENSIONS,basisSize,basisSize,numberOfVariables);
//  
//  std::cout << "lFhbnd2={" <<std::endl;
//  for (int d=0; d<6; d++) {
//    for (int v=0; v<1; v++) {
//      for (int i=0; i<basisSize; i++) {
//        for (int j=0; j<basisSize; j++) {
//          std::cout << lFhbnd2[idx_lFhbnd(d,i,j,v)] << ",";
//        }
//        std::cout << std::endl;
//      }
//    }
//    std::cout << "\\" << std::endl;
//  }
//  std::cout << "}" << std::endl;
//  
//  std::cout << "lFhbnd={" <<std::endl;
//  for (int d=0; d<6; d++) {
//    for (int v=0; v<1; v++) {
//      for (int i=0; i<basisSize; i++) {
//        for (int j=0; j<basisSize; j++) {
//          std::cout << lFhbnd[idx_lFhbnd(d,i,j,v)] << ",";
//        }
//        std::cout << std::endl;
//      }
//    }
//    std::cout << "\\" << std::endl;
//  }
//  std::cout << "}" << std::endl;
  
  //
  
//  std::cout << "lQhbnd2={" <<std::endl;
//  for (int d=0; d<6; d++) {
//    for (int v=0; v<1; v++) {
//      for (int i=0; i<basisSize; i++) {
//        for (int j=0; j<basisSize; j++) {
//          std::cout << lQhbnd2[idx_lFhbnd(d,i,j,v)] << ",";
//        }
//        std::cout << std::endl;
//      }
//    }
//    std::cout << "\\" << std::endl;
//  }
//  std::cout << "}" << std::endl;
//  
//  std::cout << "lQhbnd={" <<std::endl;
//  for (int d=0; d<6; d++) {
//    for (int v=0; v<1; v++) {
//      for (int i=0; i<basisSize; i++) {
//        for (int j=0; j<basisSize; j++) {
//          std::cout << lQhbnd[idx_lFhbnd(d,i,j,v)] << ",";
//        }
//        std::cout << std::endl;
//      }
//    }
//    std::cout << "\\" << std::endl;
//  }
//  std::cout << "}" << std::endl;
  
//  for (int i=0; i<2 * DIMENSIONS * basisSize2 *  numberOfVariables; i++) { 
//    assertion3(tarch::la::equals(lFhbnd2[i],lFhbnd[i]),i,lFhbnd2[i],lFhbnd[i]);
//  }
//  
//  for (int i=0; i<2 * DIMENSIONS * basisSize2 *  (numberOfVariables+numberOfParameters); i++) {
//    assertion3(tarch::la::equals(lQhbnd2[i],lQhbnd[i]),i,lQhbnd2[i],lQhbnd[i]);
//  }
  
  // 80,80, 80,80, 80,80
  // numberOfVariables=5
  // basisSize=4
  // basisSize2=16
  
//  delete[] lQhbnd2;
//  delete[] lFhbnd2;
}

}  // namespace c
}  // namespace generic
}  // namespace aderdg
}  // namespace kernels

#endif  // DIMENSIONS == 3
