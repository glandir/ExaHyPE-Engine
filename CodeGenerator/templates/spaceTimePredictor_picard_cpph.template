{# /**
 * This file is part of the ExaHyPE project.
 * Copyright (c) 2016  http://exahype.eu
 * All rights reserved.
 *
 * The project has received funding from the European Union's Horizon
 * 2020 research and innovation programme under grant agreement
 * No 671698. For copyrights and licensing, please consult the webpage.
 *
 * Released under the BSD 3 Open Source License.
 * For the full license text, see LICENSE.txt
 **/ #}

#include <cstring>
#include <algorithm>
#include "kernels/aderdg/optimised/Kernels.h"
#include "kernels/aderdg/optimised/DGMatrices.h"
#include "kernels/aderdg/optimised/GaussLegendreQuadrature.h"
#include "kernels/aderdg/optimised/CpphGemms.h"

template <bool useSource, bool useNCP, void PDEflux(const double* const Q, double** F), void PDEsource(const double* const Q, double* S), void PDEncp(const double* const Q, const double* const gradQ, double* BgradQ)>
void kernels::aderdg::optimised::picardLoopNonlinear(
        const double* restrict const luh, 
        const double dt,
        const tarch::la::Vector<DIMENSIONS, double>& dx,
        double* restrict lQi, double* restrict lQi_old, double* restrict rhs, double* restrict rhs_0,
        double* restrict lFi,
        double* restrict lSi, double* restrict gradQ, double* restrict BGradQ //source and ncp related term, nullptr if not used
) {


#ifdef __INTEL_COMPILER
  __assume_aligned(lQi, ALIGNMENT);
  __assume_aligned(lQi_old, ALIGNMENT);
  __assume_aligned(rhs, ALIGNMENT);
  __assume_aligned(rhs_0, ALIGNMENT);
  __assume_aligned(lFi, ALIGNMENT);
  __assume_aligned(F0, ALIGNMENT);
  __assume_aligned(s_m, ALIGNMENT);
  __assume_aligned(Kxi, ALIGNMENT);
  if(useSource || useNCP) {
    __assume_aligned(lSi, ALIGNMENT);
  }
  if(useNCP) {
    __assume_aligned(gradQ, ALIGNMENT);
    __assume_aligned(BGradQ, ALIGNMENT);
    __assume_aligned(tmp_nDof_nDofPad, ALIGNMENT);
  }
  
#endif

  if(useNCP) {
  // 0. Ensure padded BGradQ has a zero padding
    std::memset(BGradQ, 0, {{nVarPad}} * sizeof(double));

  
  // 0. precompute 1/dx * dudx_T
    const double invDx = 1.0 / dx[0];
    #pragma simd
    for(int it=0;it<{{nDof*nDofPad}};it++) {
      tmp_nDof_nDofPad[it] = invDx * dudx_T[it];
    }
    
  }

  // 1. Trivial initial guess
  for (int ijk = 0; ijk < {{nDof**nDim}}; ijk++) {
    for (int l = 0; l < {{nDof}}; l++) {
      std::copy(&luh[{{nVar}}*ijk], &luh[{{nVar}}*ijk]+{{nVar}}, &lQi[{{nVarPad}}*(l+{{nDof}}*ijk)]);
    }
  }

  // 2. Compute the contribution of the initial condition uh to the time update
  for (int i = 0; i < {{nDof3D}}; i++) {
    for (int j = 0; j < {{nDof}}; j++) {
      for (int k = 0; k < {{nDof}}; k++) {
        const double weight = {{'weights1[i] * ' if nDim == 3 else ''}} weights1[j] * weights1[k];
        #pragma simd
        for (int n = 0; n < {{nVar}}; n++) {
{% for m in nDof_seq %}
          rhs_0[n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(i+{{nDof3D*m}})))] = weight * F0[{{m}}] * luh[n+{{nVar}}*(k+{{nDof}}*(j+{{nDof}}*i))];
{% endfor %}
        }
      }
    }
  }

  // 3. Discrete Picard iterations
  const int MaxIterations = {{2 * nDof}};

  for (int iter = 0; iter < MaxIterations; iter++) {
    // Save old space-time DOF
    std::copy(&lQi[0], &lQi[0]+{{nDof**(nDim+1)*nVarPad}}, lQi_old);
    
    if(useNCP && !useSource) { //initialize lShi to 0 if used for ncp but not initialized by source terms
      std::memset(lSi, 0, {{(nDof**nDim)*nDof*nVarPad}} * sizeof(double));
    }

    for (int i = 0; i < {{nDof}}; i++) {  // time DOF
    
      // Compute the fluxes
      for (int jkl = 0; jkl < {{nDof**nDim}}; jkl++) {
        // Call PDE fluxes
        const double* Q = &lQi[{{nVarPad}}*(i+{{nDof}}*jkl)];
        double* F[{{nDim}}];
        F[0] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)];
        F[1] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)+{{1*(nDof**nDim)*nDof*nVarPad}}];
{% if nDim == 3 %}
        F[2] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)+{{2*(nDof**nDim)*nDof*nVarPad}}];
{% endif %}
        PDEflux(Q, F);
        if(useSource) { //optimised away at compile time
          PDEsource(Q,&lSi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)]);
        }
      }

      // Copy rhs0 -> rhs for slice at i
      std::copy(&rhs_0[i*{{(nDof**nDim)*nVarPad}}], &rhs_0[i*{{(nDof**nDim)*nVarPad}}]+{{(nDof**nDim)*nVarPad}}, &rhs[i*{{(nDof**nDim)*nVarPad}}]);
      
      if(useNCP) { //optimised away at compile time
        std::memset(gradQ, 0, {{(nDof**nDim)*nDof*nVarPad*nDim}} * sizeof(double));
      }
      

      // Compute the "derivatives" (contributions of the stiffness matrix)
      // x direction (independent from the y and z derivatives)
      for (int j = 0; j < {{nDof3D}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double weight = weights1[i] * {{'weights1[j] * ' if nDim == 3 else ''}} weights1[k];
          const double updateSize = weight * dt / dx[0];

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(l+{{nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i)))] -= updateSize *
                                               lFi[n+{{nVarPad}}*(m+{{nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma simd
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          {{gemm_rhs_x}}(&lFi[{{nVarPad*nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i))], &s_m[0], &rhs[{{nVarPad*nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i))]);
          if(useNCP) { 
            /* 
            for (int l = 0; l < {{nDof}}; l++) {
              for (int m = 0; m < {{nDof}}; m++) {
                #pragma simd
                for (int n = 0; n < {{nVar}}; n++) {
                  gradQ[n+{{nVar}}*(0+{{nDim}}*(i+{{nDof}}*(l+{{nDof}}*(k+{{nDof}}*j))))] += 1.0 / dx[0] *
                      lQi[n+{{nVarPad}}*(i+{{nDof}}*(m+{{nDof}}*(k+{{nDof}}*j)))] * dudx[l+{{nDofPad}}*m];
                }
              }
            } 
            */
            {{gemm_gradQ_x}}(&lQi[{{nVarPad}}*(i+{{nDof*nDof}}*(k+{{nDof}}*j))], &tmp_nDof_nDofPad[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof*nDof}}*(k+{{nDof}}*j))]);
          }          
        }
      }

      // y direction (independent from the x and z derivatives)
      for (int j = 0; j < {{nDof3D}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double weight = weights1[i] * {{'weights1[j] * ' if nDim == 3 else ''}} weights1[k];
          const double updateSize = weight * dt / dx[1];

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(k+{{nDof}}*(l+{{nDof}}*(j+{{nDof3D}}*i)))] -= updateSize *
                                               lFi[{{1*(nDof**nDim)*nDof*nVarPad}}+n+{{nVarPad}}*(k+{{nDof}}*(m+{{nDof}}*(j+{{nDof3D}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma simd
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          {{gemm_rhs_y}}(&lFi[{{1*(nDof**nDim)*nDof*nVarPad}}+{{nVarPad}}*(k+{{nDof*nDof}}*(j+{{nDof3D}}*i))], &s_m[0], &rhs[{{nVarPad}}*(k+{{nDof*nDof}}*(j+{{nDof3D}}*i))]);
          if(useNCP) {
            /*
            for (int l = 0; l < {{nDof}}; l++) {
              for (int m = 0; m < {{nDof}}; m++) {
                #pragma simd
                for (int n = 0; n < {{nVar}}; n++) {
                  gradQ[n+{{nVar}}*(1+{{nDim}}*(i+{{nDof}}*(k+{{nDof}}*(l+{{nDof}}*j))))] += 1.0 / dx[0] *
                      lQi[n+{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*(m+{{nDof}}*j)))] * dudx[l+{{nDofPad}}*m];
                }
              }
            }
            */
            {{gemm_gradQ_y}}(&lQi[{{nVarPad}}*(i+{{nDof}}*(k+{{nDof*nDof}}*j))], &tmp_nDof_nDofPad[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*(k+{{nDof*nDof}}*j))+{{nVarPad}}]);
          }
        }
      }
      
{% if nDim==3 %}
      // z direction (independent from the x and y derivatives)
      for (int j = 0; j < {{nDof}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double weight = weights1[i] *  weights1[j] * weights1[k];
          const double updateSize = weight * dt / dx[2];

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(l+{{nDof}}*i)))] -= updateSize *
                                               lFi[{{2*(nDof**nDim)*nDof*nVarPad}}+n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(m+{{nDof}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma simd
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          {{gemm_rhs_z}}(&lFi[{{2*(nDof**nDim)*nDof*nVarPad}}+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof*nDof}}*i))], &s_m[0], &rhs[{{nVarPad}}*(k+{{nDof}}*(j+{{nDof*nDof}}*i))]);
          if(useNCP) {
            /*
            for (int l = 0; l < {{nDof}}; l++) {
              for (int m = 0; m < {{nDof}}; m++) {
                #pragma simd
                for (int n = 0; n < {{nVar}}; n++) {
                  gradQ[n+{{nVar}}*(2+{{nDim}}*(i+{{nDof}}*(k+{{nDof}}*(j+{{nDof}}*l))))] += 1.0 / dx[0] *
                      lQi[n+{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*(j+{{nDof}}*m)))] * dudx[l+{{nDofPad}}*m];
                }
              }
            }
            */
            {{gemm_gradQ_z}}(&lQi[{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*j))], &tmp_nDof_nDofPad[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*(k+{{nDof}}*j))+{{2*nVarPad}}]);
          }
        }
      }
{% endif %}
      
      if(useSource || useNCP) {
        for(int jkl = 0; jkl < {{nDof**nDim}}; jkl++) { //zyx
          const double updateSize = weights1[i] * weights3[jkl] * dt;

          if(useNCP) {
            // Compute the Nonconservative part NCP. Caveats: BGradQ is a vector
            double gradQNoPad[{{nVar*nDim}}]; //remove padding to use the same user function as generic kernel
            std::copy(&gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)+{{nVar}}], &gradQNoPad[0]); //x
            std::copy(&gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)+{{nVarPad}}], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)+{{nVarPad+nVar}}], &gradQNoPad[{{nVar}}]); //y
{% if nDim==3 %}
            std::copy(&gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)+{{2*nVarPad}}],&gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*jkl)+{{2*nVarPad+nVar}}], &gradQNoPad[{{2*nVar}}]); //z
{% endif %}
            PDEncp(&lQi[{{nVarPad}}*(i+{{nDof}}*jkl)], &gradQNoPad[0], BGradQ);
          }
          
          const int shift = {{nVarPad}}*(jkl+{{nDof**nDim}}*i);
          #pragma simd
          for (int n = 0; n < {{nVarPad}}; n++) { //BgradQ is zero padded
            if(useNCP) {
              lSi[n+shift] -= BGradQ[n];
            }
            rhs[n+shift] += updateSize * lSi[n+shift];
          }
        }
      }
     
    }  // end time dof

    // 4. Multiply with (K1)^(-1) to get the discrete time integral of the
    // discrete Picard iteration
    std::memset(lQi, 0, {{(nDof**nDim) * nDof * nVarPad}} * sizeof(double));
    for (int i = 0; i < {{nDof3D}}; i++) {
      for (int j = 0; j < {{nDof}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double weight = {{'weights1[i] *' if nDim == 3 else ''}} weights1[j] *  weights1[k];
          const double iweight = 1.0 / weight;

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                lQi[n+{{nVarPad}}*(l+{{nDof}}*(k+{{nDof}}*(j+{{nDof}}*i)))] += iweight *
                                               rhs[n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(i+{{nDof3D}}*m)))] *
                                               iK1[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma simd
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = iweight * iK1[it];
          }
          {{gemm_lqh}}(&rhs[{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*i))], &s_m[0], &lQi[{{nVarPad*nDof}}*(k+{{nDof}}*(j+{{nDof}}*i))]);
        }
      }
    }

    // 5. Exit condition
    const double tol = 1e-7;
    double sq_res = 0.0;
    for (int i = 0; i < {{nDof**(nDim+1)*nVarPad}}; i++) {
      sq_res += (lQi_old[i] - lQi[i]) * (lQi_old[i] - lQi[i]);
    }
    if (sq_res < tol * tol) {
      break;
    }

    if(false) { //no debug by default
      if (iter == MaxIterations) {  // No convergence after last iteration
        static tarch::logging::Log _log("kernels::aderdg::optimised");
        logWarning("picardLoop(...)",
                   "|res|^2=" << sq_res << " > |tol|^2=" << tol * tol << " after "
                              << iter << " iterations. Solver seems not to "
                                         "have converged properly within "
                                         "maximum number of iteration steps");
      }
    }
  }  // end iter
}