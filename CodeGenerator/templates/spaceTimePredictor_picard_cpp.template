{# /**
 * This file is part of the ExaHyPE project.
 * Copyright (c) 2016  http://exahype.eu
 * All rights reserved.
 *
 * The project has received funding from the European Union's Horizon
 * 2020 research and innovation programme under grant agreement
 * No 671698. For copyrights and licensing, please consult the webpage.
 *
 * Released under the BSD 3 Open Source License.
 * For the full license text, see LICENSE.txt
 **/ #}

#include <cstring>
#include <algorithm>

#include "{{pathToOptKernel}}/Kernels.h"
#include "{{pathToOptKernel}}/DGMatrices.h"
#include "{{pathToOptKernel}}/GaussLegendreQuadrature.h"

#include "{{pathToOptKernel}}/asm_picard.c"

#include "{{solverHeader}}"

void kernels::aderdg::optimised::picardLoopNonlinear(
        {{solverName}}& solver,
        const double* restrict const luh, 
        const double dt,
        const tarch::la::Vector<DIMENSIONS, double>& inverseDx,
        double* restrict lQi, double* restrict rhs,
        double* restrict lFi,
        double* restrict lSi, double* restrict gradQ, double* restrict BGradQ //source and ncp related term, nullptr if not used //TODO JMG BGradQ not used anymore
{% if useDeepProfiler %}
        , exahype::profilers::Profiler* profiler
{% endif %}
) {

#ifdef __INTEL_COMPILER
  __assume_aligned(lQi, ALIGNMENT);
  __assume_aligned(rhs, ALIGNMENT);
  __assume_aligned(lFi, ALIGNMENT);
  __assume_aligned(FLCoeff, ALIGNMENT); // == F0
  __assume_aligned(Kxi, ALIGNMENT);
  __assume_aligned(iK1, ALIGNMENT);
  __assume_aligned(weights3, ALIGNMENT);
  __assume_aligned(luh, ALIGNMENT); //luh should be aligned, see Solver.h
{% if useSourceOrNCP %}
  __assume_aligned(lSi, ALIGNMENT);
{% endif %}
{% if useNCP %}
  __assume_aligned(gradQ, ALIGNMENT);
{% endif %}
 
#endif

  // 0. Allocate local variable
  double s_m[{{nDof*nDofPad}}] __attribute__((aligned(ALIGNMENT))); //for the gemms with alpha*Kxi or alpha*iK1
  double new_lQi_slice[{{nDof*nVarPad}}] __attribute__((aligned(ALIGNMENT))); //for step 4 (computing new lQi value)
  const double dtBydx = inverseDx[0] * dt; //Assume dx[0] == dx[1] == dx[2]
  int ijk_; //helper counter
  
{% if useNCP %}
  double dudxT_by_dx[{{nDof*nDofPad}}] __attribute__((aligned(ALIGNMENT)));
  
  // 0. precompute 1/dx * dudx_T. Assume dx[0] == dx[1] == dx[2]
  #pragma simd
  for(int it=0;it<{{nDof*nDofPad}};it++) {
    dudxT_by_dx[it] = inverseDx[0] * dudx_T[it];
  }    
{% endif %}

  // 1. Trivial initial guess
  for (int ijk = 0; ijk < {{nDof**nDim}}; ijk++) {
    for (int l = 0; l < {{nDof}}; l++) {
      std::copy(&luh[{{nVar}}*ijk], &luh[{{nVar}}*ijk]+{{nVar}}, &lQi[{{nVarPad}}*(l+{{nDof}}*ijk)]);
    }
  }


  // 2. Compute the contribution of the initial condition uh to the time update
  // we compute rhs on the fly, TODO JMG clean legacy
  
  // 3. Discrete Picard iterations
  const int MaxIterations = {{2 * nDof}};

  for (int iter = 0; iter < MaxIterations; iter++) {
    for (int i = 0; i < {{nDof}}; i++) {  // time DOF
    
      // Compute the fluxes
      for (int jkl = 0; jkl < {{nDof**nDim}}; jkl++) {
        // Call PDE fluxes
        const double* Q = &lQi[{{nVarPad}}*(i+{{nDof}}*jkl)];
        double* F[{{nDim}}];
        F[0] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)];
        F[1] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)+{{1*(nDof**nDim)*nDof*nVarPad}}];
{% if nDim == 3 %}
        F[2] = &lFi[{{nVarPad}}*(jkl+{{nDof**nDim}}*i)+{{2*(nDof**nDim)*nDof*nVarPad}}];
{% endif %}
{% if useDeepProfiler %}
        profiler->stop("spaceTimePredictor");
        profiler->start("spaceTimePredictor_PDEflux");
{% endif %}
#ifdef USE_IPO
        #pragma forceinline recursive
#endif
        solver.{{solverName}}::flux(Q, F);
{% if useDeepProfiler %}
        profiler->stop("spaceTimePredictor_PDEflux");
{% endif %}
{% if useDeepProfiler %}
        profiler->start("spaceTimePredictor_overhead");
        profiler->stop("spaceTimePredictor_overhead"); 
        profiler->start("spaceTimePredictor");
{% endif %}
      }

      // Compute the contribution of the initial condition uh to the right-hand side (rhs)
      for (int jkl = 0; jkl < {{nDof**nDim}}; jkl++) {
        const double weight = weights3[jkl] * FLCoeff[i];
        #pragma simd
        for (int n = 0; n < {{nVar}}; n++) {
          rhs[n+{{nVarPad}}*(jkl+{{nDof**nDim}}*i)] = weight * luh[n+{{nVar}}*jkl];
        }
      }
      
{% if useNCP %}
      //set gradQ to 0
      std::memset(gradQ, 0, {{(nDof**nDim)*nDof*nVarPad*nDim}} * sizeof(double));
{% endif %}
      

      // Compute the "derivatives" (contributions of the stiffness matrix)      
      // x direction (independent from the y and z derivatives)
      ijk_=i*{{nDof*nDof3D}};
      for (int j = 0; j < {{nDof3D}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double updateSize = weights3[ijk_] * dtBydx;

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(l+{{nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i)))] -= updateSize *
                                               lFi[n+{{nVarPad}}*(m+{{nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma vector aligned
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          #pragma forceinline
          {{gemm_rhs_x}}(&lFi[{{nVarPad*nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i))], &s_m[0], &rhs[{{nVarPad*nDof}}*(k+{{nDof}}*(j+{{nDof3D}}*i))]);
{% if useNCP %}
          /* 
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                gradQ[n+{{nVar}}*(0+{{nDim}}*(i+{{nDof}}*(l+{{nDof}}*(k+{{nDof}}*j))))] += inverseDx[0] *
                    lQi[n+{{nVarPad}}*(i+{{nDof}}*(m+{{nDof}}*(k+{{nDof}}*j)))] * dudx[l+{{nDofPad}}*m];
              }
            }
          } 
          */
          #pragma forceinline
          {{gemm_gradQ_x}}(&lQi[{{nVarPad}}*(i+{{nDof*nDof}}*(k+{{nDof}}*j))], &dudxT_by_dx[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof*nDof}}*(k+{{nDof}}*j))]);
{% endif %}
          ijk_++;       
        }
      }

      // y direction (independent from the x and z derivatives)
      ijk_=i*{{nDof*nDof3D}};
      for (int j = 0; j < {{nDof3D}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double updateSize = weights3[ijk_] * dtBydx;

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(k+{{nDof}}*(l+{{nDof}}*(j+{{nDof3D}}*i)))] -= updateSize *
                                               lFi[{{1*(nDof**nDim)*nDof*nVarPad}}+n+{{nVarPad}}*(k+{{nDof}}*(m+{{nDof}}*(j+{{nDof3D}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma vector aligned
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          #pragma forceinline
          {{gemm_rhs_y}}(&lFi[{{1*(nDof**nDim)*nDof*nVarPad}}+{{nVarPad}}*(k+{{nDof*nDof}}*(j+{{nDof3D}}*i))], &s_m[0], &rhs[{{nVarPad}}*(k+{{nDof*nDof}}*(j+{{nDof3D}}*i))]);
{% if useNCP %}
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                gradQ[n+{{nVar}}*(1+{{nDim}}*(i+{{nDof}}*(k+{{nDof}}*(l+{{nDof}}*j))))] += inverseDx[0] *
                    lQi[n+{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*(m+{{nDof}}*j)))] * dudx[l+{{nDofPad}}*m];
              }
            }
          }
          */
          #pragma forceinline
          {{gemm_gradQ_y}}(&lQi[{{nVarPad}}*(i+{{nDof}}*(k+{{nDof*nDof}}*j))], &dudxT_by_dx[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*(k+{{nDof*nDof}}*j))+{{nVarPad}}]);
{% endif %}
          ijk_++;
        }
      }
       
{% if nDim==3 %}
      // z direction (independent from the x and y derivatives)
      ijk_=i*{{nDof*nDof}};
      for (int j = 0; j < {{nDof}}; j++) {
        for (int k = 0; k < {{nDof}}; k++) {
          const double updateSize = weights3[ijk_] * dtBydx;

          // Matrix operation
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                rhs[n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(l+{{nDof}}*i)))] -= updateSize *
                                               lFi[{{2*(nDof**nDim)*nDof*nVarPad}}+n+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof}}*(m+{{nDof}}*i)))] *
                                               Kxi[m+{{nDofPad}}*l];
              }
            }
          }
          */
          #pragma vector aligned
          for(int it=0;it<{{nDof*nDofPad}};it++) {
            s_m[it] = -updateSize * Kxi[it];
          }
          #pragma forceinline
          {{gemm_rhs_z}}(&lFi[{{2*(nDof**nDim)*nDof*nVarPad}}+{{nVarPad}}*(k+{{nDof}}*(j+{{nDof*nDof}}*i))], &s_m[0], &rhs[{{nVarPad}}*(k+{{nDof}}*(j+{{nDof*nDof}}*i))]);
{% if useNCP %}
          /*
          for (int l = 0; l < {{nDof}}; l++) {
            for (int m = 0; m < {{nDof}}; m++) {
              #pragma simd
              for (int n = 0; n < {{nVar}}; n++) {
                gradQ[n+{{nVar}}*(2+{{nDim}}*(i+{{nDof}}*(k+{{nDof}}*(j+{{nDof}}*l))))] += inverseDx [0] *
                    lQi[n+{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*(j+{{nDof}}*m)))] * dudx[l+{{nDofPad}}*m];
              }
            }
          }
          */
          #pragma forceinline
          {{gemm_gradQ_z}}(&lQi[{{nVarPad}}*(i+{{nDof}}*(k+{{nDof}}*j))], &dudxT_by_dx[0], &gradQ[{{nVarPad*nDim}}*(i+{{nDof}}*(k+{{nDof}}*j))+{{2*nVarPad}}]);
{% endif %}
          ijk_++;
        }
      }
{% endif %}
     
{% if useSourceOrNCP %}
      // Compute the Nonconservative part NCP + Source
      for(int jkl = 0; jkl < {{nDof**nDim}}; jkl++) { //zyx
        const double updateSize = weights1[i] * weights3[jkl] * dt;
        const int shift = {{nVarPad}}*(jkl+{{nDof**nDim}}*i);
        const int it = i+{{nDof}}*jkl;

        double gradQNoPad[{{nVar*nDim}}]; //remove padding to use the same user function as generic kernel
        std::copy(&gradQ[{{nVarPad*nDim}}*it]              , &gradQ[{{nVarPad*nDim}}*it+{{0*nVarPad+nVar}}], &gradQNoPad[{{0*nVar}}]); //x
        std::copy(&gradQ[{{nVarPad*nDim}}*it+{{1*nVarPad}}], &gradQ[{{nVarPad*nDim}}*it+{{1*nVarPad+nVar}}], &gradQNoPad[{{1*nVar}}]); //y
{% if nDim==3 %}
        std::copy(&gradQ[{{nVarPad*nDim}}*it+{{2*nVarPad}}], &gradQ[{{nVarPad*nDim}}*it+{{2*nVarPad+nVar}}], &gradQNoPad[{{2*nVar}}]); //z
{% endif %}

{% if useDeepProfiler %}
        profiler->stop("spaceTimePredictor");
        profiler->start("spaceTimePredictor_PDEfusedSource");
{% endif %}
#ifdef USE_IPO
        #pragma forceinline recursive
#endif   
        solver.{{solverName}}::fusedSource(&lQi[{{nVarPad}}*it], &gradQNoPad[0], &lSi[shift]);
{% if useDeepProfiler %}
        profiler->stop("spaceTimePredictor_PDEfusedSource");
        profiler->start("spaceTimePredictor");
{% endif %}
        #pragma simd
        for (int n = 0; n < {{nVarPad}}; n++) {
          rhs[n+shift] += updateSize * lSi[n+shift];
        }
      }
{% endif %}
   
    }  // end time dof

    // 4. Multiply with (K1)^(-1) to get the discrete time integral of the
    // discrete Picard iteration
    double sq_res = 0.0;
    for (int ijk = 0; ijk < {{nDof**nDim}}; ijk++) {
      const double iweight = 1.0 / weights3[ijk];

      #pragma vector aligned
      for(int it=0;it<{{nDof*nDofPad}};it++) {
        s_m[it] = iweight * iK1[it];
      }
      
      #pragma forceinline
      {{gemm_lqi}}(&rhs[{{nVarPad}}*ijk], &s_m[0], &new_lQi_slice[0]); //Note: the gemm performs C = A*B, no need to initialize C to 0
      
      for (int l = 0; l < {{nDof*nVarPad}}; l++) {
        sq_res += (new_lQi_slice[l] - lQi[l+{{nDof*nVarPad}}*ijk]) * (new_lQi_slice[l] - lQi[l+{{nDof*nVarPad}}*ijk]);
      }
      std::copy(&new_lQi_slice[0], &new_lQi_slice[0]+{{nDof*nVarPad}}, &lQi[{{nDof*nVarPad}}*ijk]);
    }

    // 5. Exit condition
    constexpr double tol = 1e-7;
    if (sq_res < tol * tol) {
      break;
    }
  }  // end iter
}
