/**
 * Tensish is a small Algebra-free Tensor library for numerical relativity.
 * 
 * Tensish follows these paradigms:
 * 
 *   1) Seperate storage (e.g. linearized stored or shadowed) from semantics
 *      (e.g. the physical meaning of entries).
 *   2) Don't implement tensor algebra (e.g. addition, multiplication,
 *      contraction, etc.). Supply instead loops and convenient syntax.
 *      This corresponds to that users don't have to write abstract index
 *      notation (high level tensor algebra) but can stick to component-wise
 *      expressions instead (like some people prefer to write on the paper).
 *   3) Verbose semantics: Adopt a hungarian notation-like extensiveness,
 *      e.g. be verbose about upper, lower or mixed indices. Allow users
 *      to have a 1:1 correspondence of Latex and C. Always display the
 *      index positions (lower or upper).
 *   4) Don't copy or allocate data if not neccessary: The shadow classes
 *      allow higher dimensional indicing without copying data by making
 *      use of (construction-time) references.
 *   5) Be extensive and use templates: Any containers can be used
 *      beyond the given ones. The "Really" classes are an example of other
 *      storage classes.
 *   6) Don't hide the internals: We use struct's everywhere instead of
 *      privateness to allow users to access raw data in our containers
 *      if neccessary.
 *
 * As a  consequence, we don't provide a compile-time algebra check. People
 * can do math wrong, i.e. write foo = foo.lo(i,j)*bar.lo(i,j). However,
 * thanks to the syntax one immediately sees that only foo.lo(i,j)*bar.up(i,j)
 * makes sense in this particular contraction.
 *
 * Written by SvenK, Aug 2017 for ExaHyPE.
 **/
#ifndef IT_REALLY_WHIPS_THE_LLAMAS_ASS
#define IT_REALLY_WHIPS_THE_LLAMAS_ASS


/* This header file needs the definition of a C preprocessor variable DIMENSIONS.
 * You should provide this in the including file, i.e.
 * 
 *    #define DIMENSIONS 3
 *    #include "tensish.cpph"
 *
 * The number of dimensions is only needed for the DFOR macro.
 */

#define DFOR(i) for(int i=0; i<DIMENSIONS; i++)

// We use "CONTRACT" as a synonym to indicate that contractions are happening.
#define CONTRACT DFOR
#define CONTRACT2(i,j) DFOR(i) DFOR(j)
#define CONTRACT3(i,j,k) DFOR(i) DFOR(j) DFOR(k)
#define CONTRACT4(i,j,k,l) DFOR(i) DFOR(j) DFOR(k) DFOR(l)

// just because it is handy to have a SQUARE macro.
#define SQ(d) ((d)*(d))

namespace tensish {
	/*****************************************************************************/
	/*                                                                           */
	/*  Storage/addressation classes                                             */
	/*                                                                           */
	/*****************************************************************************/ 
	
	/**
	* Vector (1-dimensional linear storage, i.e. just a fixed length array).
	**/
	namespace vec {
		/// Storing an array and allowing () accss.
		template<int N> struct stored {
			double data[N];
			double& operator()(int j) {return data[j];}
			const double& operator()(int j) const {return data[j];}
		};

		/// Shadows a linear storage
		struct shadow {
			double *const data;
			shadow(double* const foreign) : data(foreign) {}
			double& operator()(int j) { return data[j]; }
			const double& operator()(int j) const { return data[j]; }
		};
		
		/// same as shadow but does not allow changing the storage location
		struct const_shadow {
			const double *const data;
			const_shadow(const double* const foreign) : data(foreign) {}
			const double& operator()(int j) const { return data[j]; }
		};
	} // ns vec

	/**
	* Symmetric Matrix (2-dimensional linearized storage).
	* Examples which can be partially represented with symmetric matrices are the metric
	* and the energy-momentum tensor.
	**/
	namespace sym {
		/**
		* Computes the size of a symmetric matrix with rank N, for instance
		* N=3 for a 3x3 matrix (9 elements, with symmetry 6 independent
		* elements), so size(3):=6.
		**/
		constexpr int size(int N) { return (N*(N+1)/2); }
		
		/**
		* The index function gives the sequentialization (ordering)
		* of a symmetric matrix of any size.
		*
		* Example for 3 dimensions (each index going from 0..2):
		*
		*    g_{ij} i->  0 1 2     If [0,1,2]=[x,y,z], then
		*               +-----+    this would mean the ordering is like
		*        j    0 |0 1 3|
		*        |    1 |1 2 4|      g_ij = (gxx, gxy, gyy, gxz, gyz, gzz)
		*        V    2 |3 4 5|
		*               +-----+    Note that this is differnt to the usual
		*                          row-first ordering (xx,xy,xz,yy,yz,zz).
		**/
		constexpr int index(int i,int j) {return  j<=i ? j+(i*(i+1))/2 : i+(j*(j+1))/2; }
		
		/**
		 * A loop for the symmetric matrix. Useful for setting it's entries.
		 **/
		#define SYMFOR(i,j) DFOR(i) for(int j=0; j<=i; j++)
		
		/// Compute determinant of a symmetric matrix
		template<class T> constexpr double det(const T &lo) {
			return -lo(0,2)*lo(0,2)*lo(1,1) + 2*lo(0,1)*lo(0,2)*lo(1,2)
			-lo(0,0)*lo(1,2)*lo(1,2) - lo(0,1)*lo(0,1)*lo(2,2)
			+lo(0,0)*lo(1,1)*lo(2,2);
		}
		
		/// The Kronecker delta with two elements
		constexpr int delta(int i, int j) { return i==j ? 1 : 0; }
		
		/// Stores a linearized NxN matrix and allows 2D index access
		template<int N> struct stored {
			double data[size(N)];
			double& operator()(int i, int j) {return data[index(i,j)];}
			const double& operator()(int i, int j) const {return data[index(i,j)];}
		};

		/// Shadows (refers to) a linearized NxN and allows 2D index access
		struct shadow {
			double *const data;
			shadow(double* const foreign) : data(foreign) {}
			double& operator()(int i, int j) { return data[index(i,j)]; }
			const double& operator()(int i, int j) const { return data[index(i,j)]; }
		};
		
		/// Same as shadow but does not allow chaning the storage location
		struct const_shadow {
			const double *const data;
			const_shadow(const double* const foreign) : data(foreign) {}
			const double& operator()(int i, int j) const { return data[index(i,j)]; }
		};
	} // ns sym


	/**
	* The 3-Metric as an up/lo structure, ie. being a Full<sym::stored<3> , sym::shadow>.
	* Therefore we assume the lower metric to be stored so the upper can be completed.
	**/
	struct metric3  {
		sym::stored<3> up;
		const sym::const_shadow lo;
		
		metric3(const double* const lo_)
			: lo(lo_)
			/* up: */ { complete_from_lower(); }
		
		void complete_from_lower() {
			double d = sym::det(lo);

			up(0,0) = (-lo(1,2)*lo(1,2) + lo(1,1)*lo(2,2) );
			up(0,1) = ( lo(0,2)*lo(1,2) - lo(0,1)*lo(2,2) );
			up(1,1) = (-lo(0,2)*lo(0,2) + lo(0,0)*lo(2,2) );
			up(0,2) = (-lo(0,2)*lo(1,1) + lo(0,1)*lo(1,2) );
			up(1,2) = ( lo(0,1)*lo(0,2) - lo(0,0)*lo(1,2) );
			up(2,2) = (-lo(0,1)*lo(0,1) + lo(0,0)*lo(1,1) );

			DFOR(i) DFOR(j) up(i,j) /= d;
			//vc = sqrt(fabs(d));
		}

		// chainable raise and lower operations for vectors
		template<class Full> metric3& raise(Full vec) { DFOR(i) CONTRACT(j) vec.up(i) = up(i,j)*vec.lo(j); return *this; }
		template<class Full> metric3& lower(Full vec) { DFOR(i) CONTRACT(j) vec.lo(i) = lo(i,j)*vec.up(j); return *this; }
	};


	/*****************************************************************************/
	/*                                                                           */
	/*  Semantics                                                                */
	/*                                                                           */
	/*****************************************************************************/ 

	/// Represents a fully contravariant tensor (only upper indices)
	template<class U> struct Up {
		U up;
		Up() {}
		Up(double* const payload) : up(payload) {}
	};

	/// Represents a read-only fully contravariant tensor (only upper indices)
	template<class U> struct ConstUp {
		const U up;
		ConstUp(const double* const payload) : up(payload) {}
	};

	/// Represents a fully covariant tensor (only lower indices)
	template<class L> struct Lo {
		L lo;
		Lo() {}
		Lo(double* const payload) : lo(payload) {}
	};

	/// Represents a read-only fully covariant tensor (only lower indices)	
	template<class L> struct ConstLo {
		const L lo;
		ConstLo(const double* const payload) : lo(payload) {}
	};

	/**
	* Represents a mixed tensor with upper and lower indices.
	* The naming makes most sense for 2-tensors, i.e. ul(i,j).
	**/
	template<class M> struct Mixed {
		M ul;
	};

	/**
	* Represents a Tensor from which both the fully contravariant
	* (upper) as well as the fully covariant (lower) version is
	* accessible/stored.
	* 
	* Const* classes:
	* Represents a Full<U,L> object which is constructed by
	* passing constant data to the lower part. Therefore, the
	* lower part is supposed to be constant while the upper may
	* be changable.
	* 
	* Init* classes:
	* Represents a Full<U,L> object which is constructed by
	* passing data to the lower part, i.e. the Full<U,L> is
	* initialized.
	**/
	template<class U, class L> struct UpLo {
		U up; L lo;
		
		struct InitLo {
			U up; L lo;
			InitLo(double* const payload) : lo(payload) {}
		};
		struct InitUp {
			U up; L lo;
			InitUp(double* const payload) : up(payload) {}
		};
		struct ConstLo {
			U up; const L lo;
			ConstLo(const double* const payload) : lo(payload) {}
		};
		struct ConstUp {
			const U up; L lo;
			ConstUp(const double* const payload) : up(payload) {}
		};

	};

	template<class U, class M> struct UpSym {
		U up; // upper indices
		M ul; // upper-lower mixed (2-tensor)
		//double& lu(int i, int j) { return ul(i,j); } // ul = lu
	};

} // namespace tensish
#endif /* IT_REALLY_WHIPS_THE_LLAMAS_ASS */
